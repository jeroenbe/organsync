{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "import os, math\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import networkx as nx\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "pl.utilities.seed.seed_everything(seed=0)\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import rc, ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter, FormatStrFormatter\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "rc('text', usetex=True)\n",
    "rc('font', family='serif')\n",
    "\n",
    "# OWN MODULES\n",
    "from src.data.data_module import UNOSDataModule, UKRegDataModule, UNOS2UKRegDataModule\n",
    "from src.models.organsync import OrganSync_Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# DATA PARAMS\n",
    "data = 'UKReg'\n",
    "batch_size = 256\n",
    "synth=False\n",
    "\n",
    "root_data_dir = Path(\"datasets\").absolute()\n",
    "\n",
    "# LOAD DATA\n",
    "if data == 'UNOS':\n",
    "    project = 'organsync-net'\n",
    "    data_dir = root_data_dir / 'processed_UNOS'\n",
    "    dm = UNOSDataModule(data_dir, batch_size=batch_size, is_synth=synth)\n",
    "    dm.prepare_data()\n",
    "elif data == 'U2U':\n",
    "    project = 'organsync-net-u2u'\n",
    "    data_dir = root_data_dir / 'processed_UNOS2UKReg_no_split'\n",
    "    dm = UNOS2UKRegDataModule(data_dir, batch_size=batch_size, is_synth=synth)\n",
    "    dm.prepare_data()\n",
    "else:\n",
    "    project = 'organsync-net-ukreg'\n",
    "    data_dir = root_data_dir / 'processed_UKReg'\n",
    "    dm = UKRegDataModule(data_dir, batch_size=batch_size, is_synth=synth)\n",
    "    dm.prepare_data()\n",
    "\n",
    "dm.setup(stage='test')\n",
    "dm.setup(stage='fit')    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup(stage='fit')\n",
    " \n",
    "lr = .005\n",
    "gamma = 0.9\n",
    "lambd = 0.5\n",
    "weight_decay = 1e-3\n",
    "epochs = 30\n",
    "batch_size = 128\n",
    "num_hidden_layers = 1\n",
    "output_dim = 8\n",
    "hidden_dim = 16\n",
    "activation_type = 'relu'\n",
    "dropout_prob = 0.0\n",
    "control = False\n",
    "is_synth = False\n",
    "test_size = 0.05\n",
    "\n",
    "# CONSTRUCT MODEL\n",
    "input_dim = dm.size(1)\n",
    "model = OrganSync_Network(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    output_dim=output_dim,\n",
    "    lr=lr, gamma=gamma, lambd=lambd, weight_decay=weight_decay,\n",
    "    activation_type=activation_type,\n",
    "    dropout_prob=dropout_prob).double()\n",
    " \n",
    "# TRAIN NETWORK\n",
    "trainer = Trainer(callbacks=[], max_epochs=epochs)\n",
    "trainer.fit(model, datamodule=dm)\n",
    " \n",
    "# TEST NETWORK\n",
    "trainer.test(datamodule=dm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPRESENTATION FROM DATA\n",
    "resolution_k  = 10\n",
    "n_per_cluster = 50\n",
    "\n",
    "n = 1000\n",
    "\n",
    "X, O, Y, _ = dm.train_dataloader().dataset.dataset.tensors\n",
    "X_t, O_t, Y_t, _ = dm.test_dataloader().dataset.tensors\n",
    "\n",
    "with torch.no_grad():\n",
    "    U = model.representation(torch.cat((X, O), dim=1))\n",
    "    u = model.representation(torch.cat((X_t, O_t), dim=1))\n",
    "\n",
    "cluster= KMeans(n_clusters=resolution_k)\n",
    "\n",
    "cluster.fit(U)\n",
    "\n",
    "print('Size of c(U):', Counter(cluster.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT PATIENTS FROM CLUSTERS\n",
    "# this is done on the test set\n",
    "\n",
    "patients = np.empty((0, n_per_cluster), dtype=int)\n",
    "\n",
    "cluster_labels = np.arange(0, resolution_k, 1)\n",
    "test_cluster_labels = cluster.predict(u)\n",
    "\n",
    "for label in cluster_labels:\n",
    "    patients_of_label = np.where(test_cluster_labels == label)[0]\n",
    "    patients_in_label = patients_of_label[np.random.randint(0, len(patients_of_label), (n_per_cluster,))]\n",
    "    \n",
    "    patients = np.append(patients, patients_in_label.reshape(1, -1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PER CLUSTER BUILD u\n",
    "u_per_cluster = np.empty((0, n_per_cluster, model.output_dim))\n",
    "\n",
    "for ps in patients:\n",
    "    u_per_cluster = np.append(u_per_cluster, u[ps].view(1, n_per_cluster, -1), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_s per model -> (resolution_k, n_per_cluster, len(U)) => per (cluster, patient, a_s)\n",
    "A_s = np.empty((0, n_per_cluster, n))\n",
    "U_limited_indices = torch.randint(0, len(U), (n,))\n",
    "U_limited = U[U_limited_indices]\n",
    "U_labels = cluster.predict(U_limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PER CLUSTER COMPUTE a\n",
    "# NOTE: this cell comprises the bulk of \n",
    "#   the computation; might run long.\n",
    "\n",
    "lambda_ = .1\n",
    "\n",
    "def convex_opt(u, U, lambd):\n",
    "    a = cp.Variable(U.shape[0])\n",
    "\n",
    "    objective = cp.Minimize(cp.norm2(a@U - u)**2 + lambd * cp.norm1(a))\n",
    "    constraints = [0 <= a, a <= 1, cp.sum(a) == 1]\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "\n",
    "    _ = prob.solve(warm_start=True, solver=cp.SCS)\n",
    "\n",
    "    return a.value\n",
    "\n",
    "print('-- STARTING --')\n",
    "\n",
    "for i, u_s_in_cluster in enumerate(u_per_cluster):\n",
    "    a = Parallel(n_jobs=joblib.cpu_count())(delayed(convex_opt)(u_, U_limited, lambda_) for u_ in u_s_in_cluster)\n",
    "    A_s = np.append(A_s, np.array(a)[:].reshape(1, n_per_cluster, -1), axis=0)\n",
    "    print(f'---- finished cluster {i}')\n",
    "print('-- FINISHED --')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MATRIX FROM a\n",
    "#    INFO: every cluster connects to every other cluster.\n",
    "#      On each row, there is the amount of the column\n",
    "#      the cluster has on other clusters.\n",
    "threshold = 1e-2\n",
    "\n",
    "\n",
    "M = np.empty((resolution_k, resolution_k))\n",
    "\n",
    "filtered = np.where(A_s >= threshold, A_s, np.zeros(A_s.shape))\n",
    "\n",
    "for i, r in enumerate(M):\n",
    "    sample_U = np.repeat(U_labels[np.newaxis, :], n_per_cluster, axis=0)\n",
    "\n",
    "    sample = sample_U[filtered[i,:,:].astype(bool)]\n",
    "\n",
    "    unique, counts = np.unique(sample, return_counts=True)\n",
    "    label_distribution = dict(zip(unique, counts))\n",
    "    \n",
    "    M[i, list(label_distribution.keys())] = list(label_distribution.values())\n",
    "\n",
    "M = normalize(M, axis=1, norm='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT MATRIX (XO)\n",
    "def plot_matrix(m, require_colorbar, title):\n",
    "    rc('axes', linewidth= 4.5) \n",
    "\n",
    "    require_colorbar = True\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "    ax.set_yticks(np.arange(0,resolution_k, 1))\n",
    "    ax.set_yticklabels(np.arange(0, resolution_k, 1), fontsize=25)\n",
    "    ax.set_xticks(np.arange(0,resolution_k, 1))\n",
    "    ax.set_xticklabels(np.arange(0, resolution_k, 1), fontsize=25)\n",
    "\n",
    "    ax.set_ylabel('composed of',  fontsize=20)\n",
    "    ax.set_xlabel('contributes to',  fontsize=20)\n",
    "\n",
    "    ax.tick_params(length=10, width=2)    \n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    im = ax.imshow(m)\n",
    "\n",
    "    divider = make_axes_locatable(ax)\n",
    "\n",
    "\n",
    "    ax.set_title(title, fontsize=25)\n",
    "\n",
    "    if require_colorbar:\n",
    "        cax = divider.append_axes(\"right\", size='10%', pad=.2)\n",
    "        cax.tick_params(length=5, width=1)\n",
    "        \n",
    "        print(cax.yaxis.get_ticklabels())\n",
    "\n",
    "        fig.colorbar(im, cax=cax, ticks=np.arange(0, M.max(), .1))\n",
    "        cax.set_yticklabels([\"{:.1f}\".format(i) for i in np.arange(0, M.max(), .1)], fontsize=15)\n",
    "        \n",
    "    return fig\n",
    "\n",
    "f = plot_matrix(M, True, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE FIGURE\n",
    "# SAVE RESULTS\n",
    "fig_detail=data\n",
    "\n",
    "\n",
    "f.savefig(f'{fig_detail}_u_composition.pdf', bbox_inches = \"tight\")\n",
    "np.save(f'{fig_detail}_M', M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_name=f'{data} (semi-synth.)'\n",
    "name=f'{data}'\n",
    "\n",
    "M_l = np.load(f'./{name}_M.npy')\n",
    "f = plot_matrix(M_l, True, fig_name)\n",
    "f.savefig(f'{name}_u_composition.pdf', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE EXAMPLE\n",
    "threshold = 1e-2\n",
    "\n",
    "# GET LATEST PATIENT (in regyr)\n",
    "tmp = dm._test_processed.copy(deep=True)\n",
    "tmp.loc[:,dm.real_cols] = dm.scaler.inverse_transform(tmp[dm.real_cols])\n",
    "patient_index = 2266#tmp.regyr.argmax()\n",
    "\n",
    "X, O, _, d = dm.test_dataloader().dataset[patient_index]\n",
    "row = dm._test_processed.iloc[[patient_index]].copy(deep=True)\n",
    "row[dm.real_cols] = dm.scaler.inverse_transform(row[dm.real_cols])\n",
    "\n",
    "with torch.no_grad():\n",
    "    u_single = model.representation(torch.cat((X, O), dim=0).view(1, -1).double())\n",
    "\n",
    "a = convex_opt(u_single.flatten(), U_limited, lambda_)\n",
    "a_filtered = np.where(a >= threshold, a, np.zeros(a.shape))\n",
    "a_filtered_indices = np.nonzero(a_filtered)[0]\n",
    "\n",
    "contributors = dm._train_processed.iloc[a_filtered_indices].copy(deep=True)\n",
    "contributors.loc[:, dm.real_cols] = dm.scaler.inverse_transform(contributors[dm.real_cols])\n",
    "\n",
    "contributors['contribution'] = a_filtered[a_filtered_indices]\n",
    "\n",
    "\n",
    "row.SERUM_BILIRUBIN = np.exp(row.SERUM_BILIRUBIN)\n",
    "row.SERUM_CREATININE = np.exp(row.SERUM_CREATININE)\n",
    "\n",
    "contributors.SERUM_BILIRUBIN = np.exp(contributors.SERUM_BILIRUBIN)\n",
    "contributors.SERUM_CREATININE = np.exp(contributors.SERUM_CREATININE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTRIBUTORS\n",
    "contributors.sort_values(by='contribution', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributors.contribution.to_numpy() @ contributors.Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = dm._test_processed.copy(deep=True)\n",
    "\n",
    "D[dm.real_cols] = dm.scaler.inverse_transform(dm._test_processed[dm.real_cols])\n",
    "D.SERUM_BILIRUBIN = np.exp(D.SERUM_BILIRUBIN)\n",
    "D.SERUM_CREATININE = np.exp(D.SERUM_CREATININE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D[(D.SERUM_SODIUM == 140) & (D.regyr == 2020)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.loc[18004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "review_organsync",
   "language": "python",
   "name": "review_organsync"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
